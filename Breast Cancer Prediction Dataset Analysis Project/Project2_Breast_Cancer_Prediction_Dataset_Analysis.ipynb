{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67634ada",
   "metadata": {},
   "source": [
    "This is the second project of the Naviotech Training Program. This project is based on teh Breast Cancer Dataset Prediction Model. \n",
    "\n",
    "This Dataset uses the famous Breast Cancer Winconsin Dataset.  This project is mainly for predicting whether a tumour is Malignant(0) or Benign (1). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2c45a6",
   "metadata": {},
   "source": [
    "Here, the predictions are made on the 30 features divided into 3 categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367f812",
   "metadata": {},
   "source": [
    "Category 1 : Mean of measurements \n",
    "1. mean radius \n",
    "2. mean texture \n",
    "3. mean perimeter \n",
    "4. mean area \n",
    "5. mean smoothness \n",
    "6. mean compactness \n",
    "7. mean concavity \n",
    "8. mean concave points \n",
    "9. mean symmetry \n",
    "10. mean fractal dimension  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539f64f",
   "metadata": {},
   "source": [
    "Category 2 : Standard Error showws variation in errors \n",
    "\n",
    "11. radius_error\n",
    "12. texture_error \n",
    "13. perimeter_error\n",
    "14. area_error \n",
    "15. smoothness_error \n",
    "16. compactness_error \n",
    "17. concavity_error \n",
    "18. concave_points_error \n",
    "19. symmetry_error \n",
    "20. fractal_dimension_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a563d9d",
   "metadata": {},
   "source": [
    "Category 3:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c35c1b",
   "metadata": {},
   "source": [
    "category 2 : Standard Error (SE) \n",
    "11. radius error \n",
    "12. texture error \n",
    "13. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9ac93b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.datasets import load_breast_cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f929416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]], shape=(569, 30)),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer Wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 569\\n\\n:Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n:Attribute Information:\\n    - radius (mean of distances from center to points on the perimeter)\\n    - texture (standard deviation of gray-scale values)\\n    - perimeter\\n    - area\\n    - smoothness (local variation in radius lengths)\\n    - compactness (perimeter^2 / area - 1.0)\\n    - concavity (severity of concave portions of the contour)\\n    - concave points (number of concave portions of the contour)\\n    - symmetry\\n    - fractal dimension (\"coastline approximation\" - 1)\\n\\n    The mean, standard error, and \"worst\" or largest (mean of the three\\n    worst/largest values) of these features were computed for each image,\\n    resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n    10 is Radius SE, field 20 is Worst Radius.\\n\\n    - class:\\n            - WDBC-Malignant\\n            - WDBC-Benign\\n\\n:Summary Statistics:\\n\\n===================================== ====== ======\\n                                        Min    Max\\n===================================== ====== ======\\nradius (mean):                        6.981  28.11\\ntexture (mean):                       9.71   39.28\\nperimeter (mean):                     43.79  188.5\\narea (mean):                          143.5  2501.0\\nsmoothness (mean):                    0.053  0.163\\ncompactness (mean):                   0.019  0.345\\nconcavity (mean):                     0.0    0.427\\nconcave points (mean):                0.0    0.201\\nsymmetry (mean):                      0.106  0.304\\nfractal dimension (mean):             0.05   0.097\\nradius (standard error):              0.112  2.873\\ntexture (standard error):             0.36   4.885\\nperimeter (standard error):           0.757  21.98\\narea (standard error):                6.802  542.2\\nsmoothness (standard error):          0.002  0.031\\ncompactness (standard error):         0.002  0.135\\nconcavity (standard error):           0.0    0.396\\nconcave points (standard error):      0.0    0.053\\nsymmetry (standard error):            0.008  0.079\\nfractal dimension (standard error):   0.001  0.03\\nradius (worst):                       7.93   36.04\\ntexture (worst):                      12.02  49.54\\nperimeter (worst):                    50.41  251.2\\narea (worst):                         185.2  4254.0\\nsmoothness (worst):                   0.071  0.223\\ncompactness (worst):                  0.027  1.058\\nconcavity (worst):                    0.0    1.252\\nconcave points (worst):               0.0    0.291\\nsymmetry (worst):                     0.156  0.664\\nfractal dimension (worst):            0.055  0.208\\n===================================== ====== ======\\n\\n:Missing Attribute Values: None\\n\\n:Class Distribution: 212 - Malignant, 357 - Benign\\n\\n:Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n:Donor: Nick Street\\n\\n:Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. dropdown:: References\\n\\n  - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction\\n    for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on\\n    Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n    San Jose, CA, 1993.\\n  - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and\\n    prognosis via linear programming. Operations Research, 43(4), pages 570-577,\\n    July-August 1995.\\n  - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n    to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994)\\n    163-171.\\n',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'breast_cancer.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_breast_cancer() \n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae4a4553",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data.data, columns = data.feature_names) \n",
    "y = pd.Series(data.target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87b549ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  \n",
    "# Hre, this is the features labels which consist of all the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cc2372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean radius                0\n",
       "mean texture               0\n",
       "mean perimeter             0\n",
       "mean area                  0\n",
       "mean smoothness            0\n",
       "mean compactness           0\n",
       "mean concavity             0\n",
       "mean concave points        0\n",
       "mean symmetry              0\n",
       "mean fractal dimension     0\n",
       "radius error               0\n",
       "texture error              0\n",
       "perimeter error            0\n",
       "area error                 0\n",
       "smoothness error           0\n",
       "compactness error          0\n",
       "concavity error            0\n",
       "concave points error       0\n",
       "symmetry error             0\n",
       "fractal dimension error    0\n",
       "worst radius               0\n",
       "worst texture              0\n",
       "worst perimeter            0\n",
       "worst area                 0\n",
       "worst smoothness           0\n",
       "worst compactness          0\n",
       "worst concavity            0\n",
       "worst concave points       0\n",
       "worst symmetry             0\n",
       "worst fractal dimension    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum() \n",
    "# Here as we cn see that there are no missing values, so this model is perfect for the visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68af600c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Length: 569, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y \n",
    "# This refers to the target labels \n",
    "\n",
    "# Here 0 refers to malignant and1 refers to Benign tumor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1b7d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have to train, test and split the model on the terms \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, random_state = 42, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce947958",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.08046</td>\n",
       "      <td>...</td>\n",
       "      <td>10.310</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>21.090</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.24870</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.07398</td>\n",
       "      <td>...</td>\n",
       "      <td>26.680</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9.173</td>\n",
       "      <td>13.86</td>\n",
       "      <td>59.20</td>\n",
       "      <td>260.9</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.05988</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.06963</td>\n",
       "      <td>...</td>\n",
       "      <td>10.010</td>\n",
       "      <td>19.23</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.1</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.05087</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10.650</td>\n",
       "      <td>25.22</td>\n",
       "      <td>68.01</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.06329</td>\n",
       "      <td>...</td>\n",
       "      <td>12.250</td>\n",
       "      <td>35.19</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.7</td>\n",
       "      <td>0.14990</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10.170</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.06960</td>\n",
       "      <td>...</td>\n",
       "      <td>11.020</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8.888</td>\n",
       "      <td>14.64</td>\n",
       "      <td>58.79</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.09783</td>\n",
       "      <td>0.15310</td>\n",
       "      <td>0.08606</td>\n",
       "      <td>0.02872</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.08980</td>\n",
       "      <td>...</td>\n",
       "      <td>9.733</td>\n",
       "      <td>15.67</td>\n",
       "      <td>62.56</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.12070</td>\n",
       "      <td>0.24360</td>\n",
       "      <td>0.14340</td>\n",
       "      <td>0.04786</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.10840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>11.640</td>\n",
       "      <td>18.33</td>\n",
       "      <td>75.17</td>\n",
       "      <td>412.5</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>0.07070</td>\n",
       "      <td>0.03485</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.06520</td>\n",
       "      <td>...</td>\n",
       "      <td>13.140</td>\n",
       "      <td>29.26</td>\n",
       "      <td>85.51</td>\n",
       "      <td>521.7</td>\n",
       "      <td>0.16880</td>\n",
       "      <td>0.26600</td>\n",
       "      <td>0.28730</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.09097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>14.290</td>\n",
       "      <td>16.82</td>\n",
       "      <td>90.30</td>\n",
       "      <td>632.6</td>\n",
       "      <td>0.06429</td>\n",
       "      <td>0.02675</td>\n",
       "      <td>0.00725</td>\n",
       "      <td>0.00625</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.05376</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>20.65</td>\n",
       "      <td>94.44</td>\n",
       "      <td>684.6</td>\n",
       "      <td>0.08567</td>\n",
       "      <td>0.05036</td>\n",
       "      <td>0.03866</td>\n",
       "      <td>0.03333</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>0.06120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>13.980</td>\n",
       "      <td>19.62</td>\n",
       "      <td>91.12</td>\n",
       "      <td>599.5</td>\n",
       "      <td>0.10600</td>\n",
       "      <td>0.11330</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.06463</td>\n",
       "      <td>0.1669</td>\n",
       "      <td>0.06544</td>\n",
       "      <td>...</td>\n",
       "      <td>17.040</td>\n",
       "      <td>30.80</td>\n",
       "      <td>113.90</td>\n",
       "      <td>869.3</td>\n",
       "      <td>0.16130</td>\n",
       "      <td>0.35680</td>\n",
       "      <td>0.40690</td>\n",
       "      <td>0.18270</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>0.10550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>12.180</td>\n",
       "      <td>20.52</td>\n",
       "      <td>77.22</td>\n",
       "      <td>458.7</td>\n",
       "      <td>0.08013</td>\n",
       "      <td>0.04038</td>\n",
       "      <td>0.02383</td>\n",
       "      <td>0.01770</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.05677</td>\n",
       "      <td>...</td>\n",
       "      <td>13.340</td>\n",
       "      <td>32.84</td>\n",
       "      <td>84.58</td>\n",
       "      <td>547.8</td>\n",
       "      <td>0.11230</td>\n",
       "      <td>0.08862</td>\n",
       "      <td>0.11450</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2694</td>\n",
       "      <td>0.06878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "68         9.029         17.33           58.79      250.5          0.10660   \n",
       "181       21.090         26.57          142.70     1311.0          0.11410   \n",
       "63         9.173         13.86           59.20      260.9          0.07721   \n",
       "248       10.650         25.22           68.01      347.0          0.09657   \n",
       "60        10.170         14.88           64.55      311.9          0.11340   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "71         8.888         14.64           58.79      244.0          0.09783   \n",
       "106       11.640         18.33           75.17      412.5          0.11420   \n",
       "270       14.290         16.82           90.30      632.6          0.06429   \n",
       "435       13.980         19.62           91.12      599.5          0.10600   \n",
       "102       12.180         20.52           77.22      458.7          0.08013   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "68            0.14130         0.31300              0.04375         0.2111   \n",
       "181           0.28320         0.24870              0.14960         0.2395   \n",
       "63            0.08751         0.05988              0.02180         0.2341   \n",
       "248           0.07234         0.02379              0.01615         0.1897   \n",
       "60            0.08061         0.01084              0.01290         0.2743   \n",
       "..                ...             ...                  ...            ...   \n",
       "71            0.15310         0.08606              0.02872         0.1902   \n",
       "106           0.10170         0.07070              0.03485         0.1801   \n",
       "270           0.02675         0.00725              0.00625         0.1508   \n",
       "435           0.11330         0.11260              0.06463         0.1669   \n",
       "102           0.04038         0.02383              0.01770         0.1739   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "68                  0.08046  ...        10.310          22.65   \n",
       "181                 0.07398  ...        26.680          33.48   \n",
       "63                  0.06963  ...        10.010          19.23   \n",
       "248                 0.06329  ...        12.250          35.19   \n",
       "60                  0.06960  ...        11.020          17.45   \n",
       "..                      ...  ...           ...            ...   \n",
       "71                  0.08980  ...         9.733          15.67   \n",
       "106                 0.06520  ...        13.140          29.26   \n",
       "270                 0.05376  ...        14.910          20.65   \n",
       "435                 0.06544  ...        17.040          30.80   \n",
       "102                 0.05677  ...        13.340          32.84   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "68             65.50       324.7           0.14820            0.43650   \n",
       "181           176.50      2089.0           0.14910            0.75840   \n",
       "63             65.59       310.1           0.09836            0.16780   \n",
       "248            77.98       455.7           0.14990            0.13980   \n",
       "60             69.86       368.6           0.12750            0.09866   \n",
       "..               ...         ...               ...                ...   \n",
       "71             62.56       284.4           0.12070            0.24360   \n",
       "106            85.51       521.7           0.16880            0.26600   \n",
       "270            94.44       684.6           0.08567            0.05036   \n",
       "435           113.90       869.3           0.16130            0.35680   \n",
       "102            84.58       547.8           0.11230            0.08862   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "68           1.25200               0.17500          0.4228   \n",
       "181          0.67800               0.29030          0.4098   \n",
       "63           0.13970               0.05087          0.3282   \n",
       "248          0.11250               0.06136          0.3409   \n",
       "60           0.02168               0.02579          0.3557   \n",
       "..               ...                   ...             ...   \n",
       "71           0.14340               0.04786          0.2254   \n",
       "106          0.28730               0.12180          0.2806   \n",
       "270          0.03866               0.03333          0.2458   \n",
       "435          0.40690               0.18270          0.3179   \n",
       "102          0.11450               0.07431          0.2694   \n",
       "\n",
       "     worst fractal dimension  \n",
       "68                   0.11750  \n",
       "181                  0.12840  \n",
       "63                   0.08490  \n",
       "248                  0.08147  \n",
       "60                   0.08020  \n",
       "..                       ...  \n",
       "71                   0.10840  \n",
       "106                  0.09097  \n",
       "270                  0.06120  \n",
       "435                  0.10550  \n",
       "102                  0.06878  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train # data on which model  is trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c006c0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.47</td>\n",
       "      <td>18.60</td>\n",
       "      <td>81.09</td>\n",
       "      <td>481.9</td>\n",
       "      <td>0.09965</td>\n",
       "      <td>0.10580</td>\n",
       "      <td>0.08005</td>\n",
       "      <td>0.03821</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>0.06373</td>\n",
       "      <td>...</td>\n",
       "      <td>14.97</td>\n",
       "      <td>24.64</td>\n",
       "      <td>96.05</td>\n",
       "      <td>677.9</td>\n",
       "      <td>0.1426</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>0.2671</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.3014</td>\n",
       "      <td>0.08750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>18.94</td>\n",
       "      <td>21.31</td>\n",
       "      <td>123.60</td>\n",
       "      <td>1130.0</td>\n",
       "      <td>0.09009</td>\n",
       "      <td>0.10290</td>\n",
       "      <td>0.10800</td>\n",
       "      <td>0.07951</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05461</td>\n",
       "      <td>...</td>\n",
       "      <td>24.86</td>\n",
       "      <td>26.58</td>\n",
       "      <td>165.90</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.2336</td>\n",
       "      <td>0.2687</td>\n",
       "      <td>0.17890</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.06589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>15.46</td>\n",
       "      <td>19.48</td>\n",
       "      <td>101.70</td>\n",
       "      <td>748.9</td>\n",
       "      <td>0.10920</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.14660</td>\n",
       "      <td>0.08087</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.05796</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>124.90</td>\n",
       "      <td>1156.0</td>\n",
       "      <td>0.1546</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>0.15140</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.08019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>12.40</td>\n",
       "      <td>17.68</td>\n",
       "      <td>81.47</td>\n",
       "      <td>467.8</td>\n",
       "      <td>0.10540</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.07741</td>\n",
       "      <td>0.02799</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.07102</td>\n",
       "      <td>...</td>\n",
       "      <td>12.88</td>\n",
       "      <td>22.91</td>\n",
       "      <td>89.61</td>\n",
       "      <td>515.8</td>\n",
       "      <td>0.1450</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>0.07370</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.09359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>11.54</td>\n",
       "      <td>14.44</td>\n",
       "      <td>74.65</td>\n",
       "      <td>402.9</td>\n",
       "      <td>0.09984</td>\n",
       "      <td>0.11200</td>\n",
       "      <td>0.06737</td>\n",
       "      <td>0.02594</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>...</td>\n",
       "      <td>12.26</td>\n",
       "      <td>19.68</td>\n",
       "      <td>78.78</td>\n",
       "      <td>457.8</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>0.2118</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>0.2329</td>\n",
       "      <td>0.08134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>14.64</td>\n",
       "      <td>16.85</td>\n",
       "      <td>94.21</td>\n",
       "      <td>666.0</td>\n",
       "      <td>0.08641</td>\n",
       "      <td>0.06698</td>\n",
       "      <td>0.05192</td>\n",
       "      <td>0.02791</td>\n",
       "      <td>0.1409</td>\n",
       "      <td>0.05355</td>\n",
       "      <td>...</td>\n",
       "      <td>16.46</td>\n",
       "      <td>25.44</td>\n",
       "      <td>106.00</td>\n",
       "      <td>831.0</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.07828</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.06596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>16.07</td>\n",
       "      <td>19.65</td>\n",
       "      <td>104.10</td>\n",
       "      <td>817.7</td>\n",
       "      <td>0.09168</td>\n",
       "      <td>0.08424</td>\n",
       "      <td>0.09769</td>\n",
       "      <td>0.06638</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.05391</td>\n",
       "      <td>...</td>\n",
       "      <td>19.77</td>\n",
       "      <td>24.56</td>\n",
       "      <td>128.80</td>\n",
       "      <td>1223.0</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.06387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>11.52</td>\n",
       "      <td>14.93</td>\n",
       "      <td>73.87</td>\n",
       "      <td>406.3</td>\n",
       "      <td>0.10130</td>\n",
       "      <td>0.07808</td>\n",
       "      <td>0.04328</td>\n",
       "      <td>0.02929</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>0.06168</td>\n",
       "      <td>...</td>\n",
       "      <td>12.65</td>\n",
       "      <td>21.19</td>\n",
       "      <td>80.88</td>\n",
       "      <td>491.8</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.1804</td>\n",
       "      <td>0.09608</td>\n",
       "      <td>0.2664</td>\n",
       "      <td>0.07809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>14.22</td>\n",
       "      <td>27.85</td>\n",
       "      <td>92.55</td>\n",
       "      <td>623.9</td>\n",
       "      <td>0.08223</td>\n",
       "      <td>0.10390</td>\n",
       "      <td>0.11030</td>\n",
       "      <td>0.04408</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.06129</td>\n",
       "      <td>...</td>\n",
       "      <td>15.75</td>\n",
       "      <td>40.54</td>\n",
       "      <td>102.50</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.08219</td>\n",
       "      <td>0.1890</td>\n",
       "      <td>0.07796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>20.73</td>\n",
       "      <td>31.12</td>\n",
       "      <td>135.70</td>\n",
       "      <td>1419.0</td>\n",
       "      <td>0.09469</td>\n",
       "      <td>0.11430</td>\n",
       "      <td>0.13670</td>\n",
       "      <td>0.08646</td>\n",
       "      <td>0.1769</td>\n",
       "      <td>0.05674</td>\n",
       "      <td>...</td>\n",
       "      <td>32.49</td>\n",
       "      <td>47.16</td>\n",
       "      <td>214.00</td>\n",
       "      <td>3432.0</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2644</td>\n",
       "      <td>0.3442</td>\n",
       "      <td>0.16590</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>0.08218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "204        12.47         18.60           81.09      481.9          0.09965   \n",
       "70         18.94         21.31          123.60     1130.0          0.09009   \n",
       "131        15.46         19.48          101.70      748.9          0.10920   \n",
       "431        12.40         17.68           81.47      467.8          0.10540   \n",
       "540        11.54         14.44           74.65      402.9          0.09984   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "486        14.64         16.85           94.21      666.0          0.08641   \n",
       "75         16.07         19.65          104.10      817.7          0.09168   \n",
       "249        11.52         14.93           73.87      406.3          0.10130   \n",
       "238        14.22         27.85           92.55      623.9          0.08223   \n",
       "265        20.73         31.12          135.70     1419.0          0.09469   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "204           0.10580         0.08005              0.03821         0.1925   \n",
       "70            0.10290         0.10800              0.07951         0.1582   \n",
       "131           0.12230         0.14660              0.08087         0.1931   \n",
       "431           0.13160         0.07741              0.02799         0.1811   \n",
       "540           0.11200         0.06737              0.02594         0.1818   \n",
       "..                ...             ...                  ...            ...   \n",
       "486           0.06698         0.05192              0.02791         0.1409   \n",
       "75            0.08424         0.09769              0.06638         0.1798   \n",
       "249           0.07808         0.04328              0.02929         0.1883   \n",
       "238           0.10390         0.11030              0.04408         0.1342   \n",
       "265           0.11430         0.13670              0.08646         0.1769   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "204                 0.06373  ...         14.97          24.64   \n",
       "70                  0.05461  ...         24.86          26.58   \n",
       "131                 0.05796  ...         19.26          26.00   \n",
       "431                 0.07102  ...         12.88          22.91   \n",
       "540                 0.06782  ...         12.26          19.68   \n",
       "..                      ...  ...           ...            ...   \n",
       "486                 0.05355  ...         16.46          25.44   \n",
       "75                  0.05391  ...         19.77          24.56   \n",
       "249                 0.06168  ...         12.65          21.19   \n",
       "238                 0.06129  ...         15.75          40.54   \n",
       "265                 0.05674  ...         32.49          47.16   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "204            96.05       677.9            0.1426             0.2378   \n",
       "70            165.90      1866.0            0.1193             0.2336   \n",
       "131           124.90      1156.0            0.1546             0.2394   \n",
       "431            89.61       515.8            0.1450             0.2629   \n",
       "540            78.78       457.8            0.1345             0.2118   \n",
       "..               ...         ...               ...                ...   \n",
       "486           106.00       831.0            0.1142             0.2070   \n",
       "75            128.80      1223.0            0.1500             0.2045   \n",
       "249            80.88       491.8            0.1389             0.1582   \n",
       "238           102.50       764.0            0.1081             0.2426   \n",
       "265           214.00      3432.0            0.1401             0.2644   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "204           0.2671               0.10150          0.3014   \n",
       "70            0.2687               0.17890          0.2551   \n",
       "131           0.3791               0.15140          0.2837   \n",
       "431           0.2403               0.07370          0.2556   \n",
       "540           0.1797               0.06918          0.2329   \n",
       "..               ...                   ...             ...   \n",
       "486           0.2437               0.07828          0.2455   \n",
       "75            0.2829               0.15200          0.2650   \n",
       "249           0.1804               0.09608          0.2664   \n",
       "238           0.3064               0.08219          0.1890   \n",
       "265           0.3442               0.16590          0.2868   \n",
       "\n",
       "     worst fractal dimension  \n",
       "204                  0.08750  \n",
       "70                   0.06589  \n",
       "131                  0.08019  \n",
       "431                  0.09359  \n",
       "540                  0.08134  \n",
       "..                       ...  \n",
       "486                  0.06596  \n",
       "75                   0.06387  \n",
       "249                  0.07809  \n",
       "238                  0.07796  \n",
       "265                  0.08218  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test # data on which model is tested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d5d30aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68     1\n",
       "181    0\n",
       "63     1\n",
       "248    1\n",
       "60     1\n",
       "      ..\n",
       "71     1\n",
       "106    1\n",
       "270    1\n",
       "435    0\n",
       "102    1\n",
       "Length: 455, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train # data on which model is trained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26d6eae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204    1\n",
       "70     0\n",
       "131    0\n",
       "431    1\n",
       "540    1\n",
       "      ..\n",
       "486    1\n",
       "75     0\n",
       "249    1\n",
       "238    1\n",
       "265    0\n",
       "Length: 114, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test # data on which the model is tested "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c292d738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we have to scale the feature, before the machine learning can be applied to it. \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler() \n",
    "\n",
    "x_train = sc.fit_transform(x_train) \n",
    "x_test = sc.transform(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "106833b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_estimators&nbsp;</td>\n",
       "            <td class=\"value\">500</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">criterion&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_depth&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_split&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_samples_leaf&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_weight_fraction_leaf&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_features&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_leaf_nodes&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">min_impurity_decrease&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">bootstrap&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">oob_score&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">-1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">42</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">verbose&nbsp;</td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">class_weight&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">ccp_alpha&nbsp;</td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_samples&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">monotonic_cst&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will apply the machine learning algorithm \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "model = RandomForestClassifier(random_state = 42, n_estimators = 500, n_jobs = -1) \n",
    "classifier = model.fit(x_train, y_train) \n",
    "classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62c4369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test) \n",
    "y_pred  \n",
    "# Here are all the predictions of the x_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b843ba4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.964, 0.004, 0.004, 0.996, 1.   , 0.   , 0.   , 0.108, 0.314,\n",
       "       0.972, 0.946, 0.032, 0.91 , 0.162, 0.99 , 0.032, 0.96 , 0.996,\n",
       "       0.998, 0.002, 0.832, 0.998, 0.   , 0.998, 0.994, 0.93 , 0.994,\n",
       "       0.94 , 0.998, 0.   , 0.992, 0.998, 0.806, 0.948, 1.   , 1.   ,\n",
       "       0.266, 0.948, 0.002, 0.904, 0.998, 0.014, 0.998, 1.   , 0.738,\n",
       "       0.99 , 0.91 , 0.96 , 0.99 , 0.982, 0.012, 0.   , 0.752, 0.852,\n",
       "       0.996, 0.976, 0.998, 0.002, 0.262, 0.998, 0.996, 0.   , 0.002,\n",
       "       0.918, 1.   , 0.854, 0.   , 0.008, 0.998, 0.968, 0.148, 0.008,\n",
       "       0.988, 0.   , 0.988, 0.956, 0.95 , 0.732, 1.   , 0.934, 0.034,\n",
       "       1.   , 0.688, 0.002, 0.164, 0.014, 0.132, 0.02 , 0.984, 0.992,\n",
       "       0.994, 0.784, 0.81 , 0.932, 0.998, 1.   , 0.   , 0.006, 1.   ,\n",
       "       0.01 , 0.064, 1.   , 0.004, 0.   , 0.976, 0.992, 0.994, 0.004,\n",
       "       0.57 , 0.886, 0.01 , 1.   , 0.704, 0.   ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will make the predictions probability on the x_test \n",
    "y_prob = classifier.predict_proba(x_test)[:,1] \n",
    "y_prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c8b20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy:  0.9649122807017544\n",
      "Confusion Matrix: \n",
      " [[40  3]\n",
      " [ 1 70]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "ROC AUC Score:  0.9957418932197838\n"
     ]
    }
   ],
   "source": [
    "# Now, we have to make the evaluations after the model is trained and the machine laearning is applied \n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score \n",
    "\n",
    "print(\"Acuracy: \", accuracy_score(y_test, y_pred)) \n",
    "\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(y_test, y_pred)) \n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred)) \n",
    "\n",
    "print(\"ROC AUC Score: \", roc_auc_score(y_test, y_prob)) \n",
    "\n",
    "# Here the accuracy shown is being around 96.4 percent \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45709748",
   "metadata": {},
   "source": [
    "Now, we have to plot some graphs  to make the model and the predictions more interesting and onbservable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd2cedce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import confusion_matrix \n",
    "import seaborn as sns \n",
    "\n",
    "cm =  confusion_matrix(y_test, y_pred) \n",
    "\n",
    "plt.figure() \n",
    "sns.heatmap(cm, annot = True, fmt = 'd')  \n",
    "\n",
    "plt.xlabel(\"Predicted\") \n",
    "plt.ylabel(\"Actual\") \n",
    "\n",
    "plt.title(\"Confusion Matrix\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f446a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_prob = classifier.predict_proba(x_test)[:,1] \n",
    "\n",
    "plt.figure() \n",
    "plt.hist(y_prob, bins = 20) \n",
    "plt.xlabel(\"Predicted Probability (Benign)\") \n",
    "plt.ylabel(\"Count\") \n",
    "plt.title(\"Prediction Probability Distribution\") \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce53d6d",
   "metadata": {},
   "source": [
    "Now, after all the preictions, we have to make the predictions toprove the working of the Machine Learning Project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1351b717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91981\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Malignant Tumor\n"
     ]
    }
   ],
   "source": [
    "sample = x.iloc[0].values.reshape(1,-1) \n",
    "sample = sc.transform(sample) \n",
    "\n",
    "prediction = classifier.predict(sample) \n",
    "\n",
    "print(prediction[0]) \n",
    "\n",
    "if prediction[0] == 1: \n",
    "    print(\"Benign Tumor\") \n",
    "\n",
    "else: \n",
    "    print(\"Malignant Tumor\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28dc8c",
   "metadata": {},
   "source": [
    "                                    Now, we ahve to make the predictions on the  new data for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f89255f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91981\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "new_patient = np.array([\n",
    "    14.5, 20.3, 95.1, 650.2, 0.10,\n",
    "    0.18, 0.20, 0.09, 0.18, 0.06,\n",
    "    0.25, 1.30, 2.50, 30.0, 0.01,\n",
    "    0.04, 0.05, 0.02, 0.02, 0.003,\n",
    "    16.5, 25.1, 110.0, 800.5, 0.14,\n",
    "    0.30, 0.32, 0.15, 0.28, 0.09\n",
    "]).reshape(1, -1) \n",
    "\n",
    "new_patient = sc.transform(new_patient) \n",
    "\n",
    "prediction = classifier.predict(new_patient) \n",
    "\n",
    "probability = classifier.predict_proba(new_patient)[0][1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2744ee0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Malignant\n",
      "Probability: 0.348\n"
     ]
    }
   ],
   "source": [
    "if prediction[0] == 1: \n",
    "    print(\"Prediction: Benign\") \n",
    "    print(f\"Probability: {probability}\") \n",
    "\n",
    "else: \n",
    "    print(\"Prediction: Malignant\")\n",
    "    print(f\"Probability: {probability}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
